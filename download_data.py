
import kagglehub
import pandas as pd
import os
import shutil

# 1. Download dataset
print("â³ Downloading huge dataset from Kaggle...")
path = kagglehub.dataset_download("tsiaras/uk-road-safety-accidents-and-vehicles")
print(f"âœ… Download complete at: {path}")

# 2. Find the correct CSV file
csv_file = os.path.join(path, "Accident_Information.csv")
if not os.path.exists(csv_file):
    for f in os.listdir(path):
        if f.endswith('.csv') and 'Accident' in f:
            csv_file = os.path.join(path, f)
            break

# 3. Process and Save (To replace the old small file)
print("âš™ï¸ Processing and replacing the old dataset...")

# ÙÙ‚Ø· Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ… Ú©Ù‡ Ø­Ø¬Ù… Ø§Ù„Ú©ÛŒ Ø¨Ø§Ù„Ø§ Ù†Ø±ÙˆØ¯
needed_columns = [
    'Accident_Severity', 'Date', 'Time', 'Latitude', 'Longitude', 
    'Speed_limit', 'Light_Conditions', 'Weather_Conditions', 
    'Road_Surface_Conditions', 'Urban_or_Rural_Area'
]

# Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ (Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø²Ù…Ø§Ù†â€ŒØ¨Ø± Ø¨Ø§Ø´Ø¯)
df = pd.read_csv(csv_file, low_memory=False)

# Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ (Ø§Ú¯Ø± Ø¯Ø± Ø¯ÛŒØªØ§ÛŒ Ø¬Ø¯ÛŒØ¯ Ù…ØªÙØ§ÙˆØª Ø¨ÙˆØ¯)
# Ø§ÛŒÙ†Ø¬Ø§ ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø¯ÛŒØªØ§ÛŒ Kaggle Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø§Ø³ØªØŒ Ø§Ù…Ø§ Ù…Ø­Ø¶ Ø§Ø­ØªÛŒØ§Ø·:
df.rename(columns={'accident_severity': 'Accident_Severity'}, inplace=True) 

# Ø§Ù†ØªØ®Ø§Ø¨ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ùˆ Ø­Ø°Ù Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ
df = df[needed_columns].dropna()

# Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ù…Ø³ÛŒØ± Ù¾Ø±ÙˆÚ˜Ù‡ Ø´Ù…Ø§
output_path = 'data/cleaned_accident_data.csv'

# Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ù¾ÙˆØ´Ù‡ data
os.makedirs('data', exist_ok=True)

df.to_csv(output_path, index=False)

print(f"âœ… SUCCESS! The dataset has been updated.")
print(f"ğŸ“ Location: {output_path}")
print(f"ğŸ“Š New Size: {len(df)} records (Huge Upgrade!)")